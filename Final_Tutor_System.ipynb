{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIkzqeXsqGK8"
      },
      "outputs": [],
      "source": [
        "#Question Answering system using a pdf\\\n",
        "# Below is testing code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2X4pBfwqNWm",
        "outputId": "0c09f0d5-3293-40de-f177-e0ac6e423836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in _compute_dependencies\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in <listcomp>\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3086, in reqs_for_extra\n",
            "    if not req.marker or req.marker.evaluate({'extra': extra}):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 310, in evaluate\n",
            "    current_environment = cast(\"dict[str, str]\", default_environment())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 250, in default_environment\n",
            "    \"platform_release\": platform.release(),\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 169, in __init__\n",
            "    sum(\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.2.14 requires openai<2.0.0,>=1.58.1, but you have openai 1.57.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting Flask==2.3.2\n",
            "  Downloading Flask-2.3.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.3.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask==2.3.2) (3.0.2)\n",
            "Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Flask\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Flask-2.3.2\n"
          ]
        }
      ],
      "source": [
        "#Install the libraries\n",
        "!pip install -q langchain\n",
        "!pip install -q langchain_community\n",
        "!pip install -q langchain_openai\n",
        "!pip install -q openai==1.57.0\n",
        "!pip install -q langchain_core\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb\n",
        "!pip install Flask==2.3.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mtv-MxsyqQAn"
      },
      "outputs": [],
      "source": [
        "##Imports for Baseline QA Pipeline\n",
        "from langchain.document_loaders import PyPDFLoader # for loading the pdf\n",
        "from langchain_openai import OpenAIEmbeddings # for creating embeddings\n",
        "from langchain.vectorstores import Chroma # for the vectorization part\n",
        "from langchain.chains import RetrievalQA #For the retrieval QA chain part\n",
        "from langchain_openai import ChatOpenAI #for getting an LLM for QA chain\n",
        "#from langchain_core.output_parsers import StrOutputParser #Not used currently, leaving, as can be used for parsing output from LLM\n",
        "#from langchain_core.runnables import RunnablePassthrough #Not used currently, leaving, as can be used for getting LLM output\n",
        "from langchain.prompts import ChatPromptTemplate #for setting up prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOSdAp8mqRX5"
      },
      "outputs": [],
      "source": [
        "#Setup openai key\n",
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "OPENAI_API_KEY = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a96_ARBwtZEE",
        "outputId": "8d8525b4-b27a-4791-dff9-a1fe61819179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.8M  100 10.8M    0     0  18.6M      0 --:--:-- --:--:-- --:--:-- 18.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    69    0    69    0     0    241      0 --:--:-- --:--:-- --:--:--   242\n"
          ]
        }
      ],
      "source": [
        "#Download a sample pdf\n",
        "!curl https://www.mrbigler.com/downloads/Notes-Physics-1.pdf >Notes_Physics.pdf\n",
        "!curl https://app.onecompiler.com/42z9je4e9_42zkvjjnh/ > index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6reJ1IoqVrK"
      },
      "outputs": [],
      "source": [
        "#Setup Base QA system pipeline\n",
        "class BaseQAPipeline:\n",
        "    def __init__(self):\n",
        "        self.doc = \"tutor_textbook.pdf\"\n",
        "        self.loader = PyPDFLoader(self.doc)\n",
        "\n",
        "        # Load the document and store it in the 'data' variable\n",
        "        self.data = self.loader.load_and_split()\n",
        "\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        self.vectordb = Chroma.from_documents(self.data, embedding=self.embeddings,\n",
        "                                 persist_directory=\".\")\n",
        "\n",
        "        # Initialize a language model with ChatOpenAI\n",
        "        self.llm = ChatOpenAI(model_name= 'gpt-3.5-turbo', temperature=0.6)\n",
        "\n",
        "        #Setup a prompt template\n",
        "        template = \"\"\"\\\n",
        "        You are an assistant for question-answering tasks.\n",
        "\n",
        "        Use the following pieces of retrieved context to answer the question.\n",
        "\n",
        "        If you don't know the answer, just say that you don't know.\n",
        "\n",
        "        Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Context: {context}\n",
        "\n",
        "        Answer:\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        chain_type_kwargs = {\"prompt\": prompt}\n",
        "\n",
        "\n",
        "\n",
        "        # 1. Vectorstore-based retriever\n",
        "        self.vectorstore_retriever = self.vectordb.as_retriever()\n",
        "\n",
        "        # Initialize a RetrievalQA chain with the language model and vector database retriever\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(self.llm, retriever= self.vectorstore_retriever, chain_type_kwargs=chain_type_kwargs)\n",
        "\n",
        "\n",
        "    def invoke(self, input_dict):\n",
        "        question = input_dict.get(\"question\")\n",
        "        context = input_dict.get(\"context\")\n",
        "        result = self.qa_chain.invoke({\"query\": question}, {\"context\": context})\n",
        "        return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "0tUCW5XKgxul",
        "outputId": "612cbf9b-70cf-415d-f556-2467c118ba7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://qg8uz4v9w7d-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:13] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:14] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:20] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:20] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:29] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:29] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:17:35] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:29:04] \"\u001b[33mGET /how-it-works?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:29:06] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:29:07] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:30:21] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 20:30:22] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "from werkzeug.utils import secure_filename\n",
        "import os  # For file path management\n",
        "\n",
        "\n",
        "filepath = \"./tutor_textbook.pdf\"\n",
        "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'docx', 'png', 'jpg', 'jpeg', 'gif'}\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    global url_data, prompt_data  # Access global variables\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        url_data = request.form.get(\"url\")\n",
        "        print(\"URL: \", url_data)\n",
        "        if 'file' not in request.files:\n",
        "            print('No file uploaded!')\n",
        "        else:\n",
        "          file = request.files['file']\n",
        "          file.save(filepath)\n",
        "          print(\"File saved:\", filepath)\n",
        "        if (url_data != \"\"):\n",
        "            !curl {url_data} > tutor_textbook.pdf\n",
        "        print(\"File: \",file)\n",
        "        prompt_data = request.form.get(\"prompt\")\n",
        "        base_qa_pipeline = BaseQAPipeline()\n",
        "        result = base_qa_pipeline.invoke({'question' : prompt_data})\n",
        "        print(result)\n",
        "        return render_template(\"index.html\", result=result)\n",
        "\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route('/how-it-works', methods=['GET'])\n",
        "def how_it_works():\n",
        "    return render_template('how-it-works.html')\n",
        "\n",
        "@app.route('/generate-plan', methods=['GET'])\n",
        "def generate_plan():\n",
        "    return render_template('generate-plan.html')\n",
        "\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ER0rBIrmqfpp",
        "outputId": "17f230c7-14ab-4013-9d77-f867f037eda3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'openai' has no attribute 'OpenAI'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8fea80afa8ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_qa_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseQAPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_qa_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'question'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'What is momentum?'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-9602cb5c01c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         self.vectordb = Chroma.from_documents(self.data, embedding=self.embeddings,\n\u001b[1;32m     12\u001b[0m                                  persist_directory=\".\")\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0msync_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_async_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'OpenAI'"
          ]
        }
      ],
      "source": [
        "base_qa_pipeline = BaseQAPipeline()\n",
        "result = base_qa_pipeline.invoke({'question' : 'What is momentum?'})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R3h2ufh5BSFD",
        "outputId": "9fa94993-5bb6-44b9-ce54-5dff4410bfd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask==2.3.2 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: Werkzeug>=2.3.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask==2.3.2) (3.0.2)\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting openai==1.57.0\n",
            "  Obtaining dependency information for openai==1.57.0 from https://files.pythonhosted.org/packages/ab/2d/eb8539a2d5809eb78508633a8faa8df7745960e99af0388310c43b2c0be1/openai-1.57.0-py3-none-any.whl.metadata\n",
            "  Using cached openai-1.57.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai==1.57.0)\n",
            "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/a0/7a/4daaf3b6c08ad7ceffea4634ec206faeff697526421c20f07628c7372156/anyio-4.7.0-py3-none-any.whl.metadata\n",
            "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai==1.57.0)\n",
            "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.57.0)\n",
            "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai==1.57.0)\n",
            "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/4d/a0/3993cda2e267fe679b45d0bcc2cef0b4504b0aa810659cdae9737d6bace9/jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai==1.57.0)\n",
            "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/f3/26/3e1bbe954fde7ee22a6e7d31582c642aad9e84ffe4b5fb61e63b87cd326f/pydantic-2.10.4-py3-none-any.whl.metadata\n",
            "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting sniffio (from openai==1.57.0)\n",
            "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai==1.57.0)\n",
            "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typing-extensions<5,>=4.11 (from openai==1.57.0)\n",
            "  Obtaining dependency information for typing-extensions<5,>=4.11 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.5.0->openai==1.57.0)\n",
            "  Obtaining dependency information for exceptiongroup>=1.0.2 from https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl.metadata\n",
            "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai==1.57.0)\n",
            "  Obtaining dependency information for idna>=2.8 from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai==1.57.0)\n",
            "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/a5/32/8f6669fc4798494966bf446c8c4a162e0b5d893dff088afddf76414f70e1/certifi-2024.12.14-py3-none-any.whl.metadata\n",
            "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.57.0)\n",
            "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl.metadata\n",
            "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.57.0)\n",
            "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai==1.57.0)\n",
            "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai==1.57.0)\n",
            "  Obtaining dependency information for pydantic-core==2.27.2 from https://files.pythonhosted.org/packages/32/90/3b15e31b88ca39e9e626630b4c4a1f5a0dfd09076366f4219429e6786076/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Using cached openai-1.57.0-py3-none-any.whl (389 kB)\n",
            "Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
            "Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: typing-extensions, tqdm, sniffio, jiter, idna, h11, exceptiongroup, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.12.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Removing file or directory /usr/local/bin/tqdm\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tqdm-4.67.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tqdm/\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  changing mode of /usr/local/bin/tqdm to 755\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/sniffio-1.3.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/sniffio/\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.8.2\n",
            "    Uninstalling jiter-0.8.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/jiter-0.8.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/jiter/\n",
            "      Successfully uninstalled jiter-0.8.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/idna-3.10.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/idna/\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/h11-0.14.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/h11/\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: exceptiongroup\n",
            "    Found existing installation: exceptiongroup 1.2.2\n",
            "    Uninstalling exceptiongroup-1.2.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/exceptiongroup-1.2.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/exceptiongroup/\n",
            "      Successfully uninstalled exceptiongroup-1.2.2\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Removing file or directory /usr/local/bin/distro\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/distro-1.9.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/distro/\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  changing mode of /usr/local/bin/distro to 755\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/certifi-2024.12.14.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/certifi/\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/annotated_types-0.7.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/annotated_types/\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pydantic_core-2.27.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pydantic_core/\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/httpcore-1.0.7.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/httpcore/\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.7.0\n",
            "    Uninstalling anyio-4.7.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio-4.7.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__init__.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/__init__.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/from_thread.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/lowlevel.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/pytest_plugin.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/to_process.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/__pycache__/to_thread.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_backends/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__init__.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/__init__.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_asyncio_selector_thread.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_eventloop.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_exceptions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_fileio.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_resources.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_signals.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_sockets.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_streams.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_subprocesses.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_synchronization.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_tasks.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_testing.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/__pycache__/_typedattr.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_asyncio_selector_thread.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_eventloop.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_exceptions.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_fileio.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_resources.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_signals.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_sockets.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_streams.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_subprocesses.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_synchronization.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_tasks.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_testing.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/_core/_typedattr.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__init__.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/__init__.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_eventloop.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_resources.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_sockets.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_streams.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_subprocesses.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_tasks.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/__pycache__/_testing.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_eventloop.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_resources.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_sockets.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_streams.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_subprocesses.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_tasks.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/abc/_testing.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/from_thread.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/lowlevel.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/py.typed\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/pytest_plugin.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__init__.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/__init__.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/buffered.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/file.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/memory.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/stapled.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/text.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/__pycache__/tls.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/buffered.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/file.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/memory.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/stapled.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/text.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/streams/tls.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/to_process.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\n",
            "      Successfully uninstalled anyio-4.7.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.4\n",
            "    Uninstalling pydantic-2.10.4:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pydantic-2.10.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pydantic/\n",
            "      Successfully uninstalled pydantic-2.10.4\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Removing file or directory /usr/local/bin/httpx\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/httpx-0.28.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/httpx/\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  changing mode of /usr/local/bin/httpx to 755\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.3\n",
            "    Uninstalling openai-1.59.3:\n",
            "      Removing file or directory /usr/local/bin/openai\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/openai-1.59.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/openai/\n",
            "      Successfully uninstalled openai-1.59.3\n",
            "  changing mode of /usr/local/bin/openai to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\n",
            "langchain-openai 0.2.14 requires openai<2.0.0,>=1.58.1, but you have openai 1.57.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.7.0 anyio-4.7.0 certifi-2024.12.14 distro-1.9.0 exceptiongroup-1.2.2 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.8.2 openai-1.57.0 pydantic-2.10.4 pydantic-core-2.27.2 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "anyio",
                  "certifi",
                  "distro",
                  "sniffio"
                ]
              },
              "id": "2ab9808709a54c1490ae53305decfdb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (4.7.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (4.12.2)\n",
            "Please enter Open AI KEY\n",
            "··········\n",
            "https://e24y6siheu9-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:36:01] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:36:01] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:41:55] \"GET /how-it-works?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:41:56] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:42:14] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:42:15] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:42:31] \"GET /?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:42:37] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:43:36] \"GET /generate-plan?authuser=0 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:43:37] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved: ./tutor_textbook.pdf\n",
            "File:  <FileStorage: 'Tipler_Llewellyn.pdf' ('application/pdf')>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2755714fafb8>:181: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  context_from_db = self.vectorstore_retriever.get_relevant_documents(\"\")\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:46:37] \"POST /generate-plan?authuser=0 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'I need help on Kinematics 1d', 'context': 'Chat history:\\n\\n\\nContext from the document:\\nThis page intentionally left blank\\nThis page intentionally left blank\\nThis page intentionally left blank\\nProblems 141\\nNotes\\n1. Democritus (about 470 B.C. to about 380 B.C.). Among his\\nother modern-sounding ideas were the suggestions that the\\nMilky Way is a vast conglomeration of stars and that the\\nMoon, like Earth, has mountains and valleys.\\n2. G. J. Stoney (1826–1911). An Irish physicist who first\\ncalled the fundamental unit of charge the electron. After\\nThomson discovered the particle that carried the charge, the\\nname was transferred from the quantity of charge to the parti-\\ncle itself by Lorentz.\\n3. Joseph J. Thomson (1856–1940). English physicist and\\ndirector for more than 30 years of the Cavendish Laboratory,\\nthe first laboratory in the world established expressly for re-\\nsearch in physics. He was awarded the Nobel Prize in 1906 for\\nhis work on the electron. Seven of his research assistants also\\nwon Nobel Prizes.\\n4. Much early confusion existed about the nature of cath-\\node rays due to the failure of Heinrich Hertz in 1883 to ob-\\nserve any deflection of the rays in an electric field. The fail-\\nure was later found to be the result of ionization of the gas in\\nthe tube; the ions quickly neutralized the charges on the\\ndeflecting plates so that there was actually no electric field\\nbetween the plates. With better vacuum technology in 1897,\\nThomson was able to work at lower pressure and observe\\nelectrostatic deflection.\\n5. R. A. Millikan, Philosophical Magazine (6), 19, 209\\n(1910). Millikan, who held the first physics Ph.D. awarded by\\nColumbia University, was one of the most accomplished ex-\\nperimentalists of his time. He received the Nobel Prize in\\n1923 for the measurement of the electron’s charge. Also\\namong his many contributions, he coined the phrase cosmic\\nrays to describe radiation produced in outer space.\\n6. R. A. Millikan, Physical Review, 32, 349 (1911).\\n7. Mohr, P. J., and B. N. Taylor, “The Fundamental Physical\\nConstants,” Physics Today (August 2004).\\n8. See pp. 135-137 of F. K. Richtmyer, E. H. Kennard, and\\nJ. N. Cooper (1969).\\n9. John W. S. Rayleigh (1842–1919). English physicist, al-\\nmost invariably referred to by the title he inherited from his\\nfather. He was Maxwell’s successor and Thomson’s predeces-\\nsor as director of the Cavendish Laboratory.\\n10. Max K. E. L. Planck (1858–1947). Most of his career was\\nspent at the University of Berlin. In his later years his renown\\nin the world of science was probably second only to that of\\nEinstein.\\n11. Heinrich R. Hertz (1857–1894), German physicist, student\\nof Helmholtz. He was the discoverer of electromagnetic “radio”\\nwaves, later developed for practical communication by Marconi.\\n12. H. Hertz, Annalen der Physik, 31, 983 (1887).\\n13. A. Einstein, Annalen der Physik, 17, 144 (1905).\\n14. A translation of this paper can be found in E. C. Watson,\\nAmerican Journal of Physics, 13, 284 (1945), and in Shamos\\n(1962). Roentgen (1845–1923) was honored in 1901 with the\\nfirst Nobel Prize in Physics for his discovery of x rays.\\n15. William Lawrence Bragg (1890–1971), Australian-English\\nphysicist. An infant prodigy, his work on x-ray diffraction per-\\nformed with his father, William Henry Bragg (1862–1942),\\nearned for them both the Nobel Prize in Physics in 1915, the\\nonly father-son team to be so honored thus far. In 1938 W. L.\\nBragg became director of the Cavendish Laboratory, succeed-\\ning Rutherford.\\n16. Arthur H. Compton (1892–1962), American physicist. It\\nwas Compton who suggested the name photon for the light\\nquantum. His discovery and explanation of the Compton ef-\\nfect earned him a share of the Nobel Prize in Physics in 1927.\\nProblems\\nLevel I\\nSection 3-1 Quantization of Electric Charge\\n3-1. A beam of charged particles consisting of protons, electrons, deuterons, and singly ion-\\nized helium atoms and molecules all pass through a velocity selector, all emerging with\\nspeeds of The beam then enters a region of uniform magnetic field \\ndirected perpendicular to their velocity. Compute the radius of curvature of the path of each type\\nof particle.', 'result': \"<p>Based on the context provided, here are 10 questions related to Kinematics 1D:</p>\\n<ol>\\n<li>How does the Lorentz transformation impact the time separation of events in different frames of reference?</li>\\n<li>Explain the concept of time dilation and how it is tested by two observers in different frames of reference.</li>\\n<li>What is the relationship between the angular speed of a compact disk in a CD-ROM drive and time intervals due to time dilation?</li>\\n<li>How do the velocities of two rockets leaving a space station perpendicular to each other relate to each other?</li>\\n<li>Describe the scenario of a system consisting of a cubic lattice of meter sticks moving at high speed and how it affects their measurements.</li>\\n<li>How does the acceleration of a particle in frame S differ from its acceleration in the frame S'?</li>\\n<li>Discuss the implications of a particle's velocity being greater than the speed of light in a reference frame.</li>\\n<li>How does the Galilean transformation differ from the Lorentz transformation in terms of accelerations in different frames of reference?</li>\\n<li>Explain the concept of pseudoforces and their application in non-inertial reference frames.</li>\\n<li>How does Newton's second law hold in different reference frames moving at constant velocities relative to each other?</li>\\n</ol>\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [05/Jan/2025 03:46:38] \"\u001b[33mGET /favicon.ico?authuser=0 HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "# Final code with everything attached.\n",
        "#Question Answering system using a pdf\n",
        "#Install the libraries\n",
        "!pip install -q langchain\n",
        "!pip install -q langchain_community\n",
        "!pip install -q langchain_openai\n",
        "!pip install -q openai\n",
        "!pip install -q langchain_core\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb\n",
        "!pip install Flask==2.3.2\n",
        "!pip install --force-reinstall -v openai==1.57.0\n",
        "!python3 -m pip install --upgrade httpx\n",
        "##Imports for Baseline QA Pipeline\n",
        "from langchain.document_loaders import PyPDFLoader # for loading the pdf\n",
        "from langchain_openai import OpenAIEmbeddings # for creating embeddings\n",
        "from langchain.vectorstores import Chroma # for the vectorization part\n",
        "from langchain.chains import RetrievalQA #For the retrieval QA chain part\n",
        "from langchain_openai import ChatOpenAI #for getting an LLM for QA chain\n",
        "#from langchain_core.output_parsers import StrOutputParser #Not used currently, leaving, as can be used for parsing output from LLM\n",
        "#from langchain_core.runnables import RunnablePassthrough #Not used currently, leaving, as can be used for getting LLM output\n",
        "from langchain.prompts import ChatPromptTemplate #for setting up prompts\n",
        "#Setup openai key\n",
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "print(\"Please enter Open AI KEY\")\n",
        "OPENAI_API_KEY = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "#Setup Base QA system pipeline\n",
        "class BaseQAPipeline:\n",
        "    def __init__(self):\n",
        "        self.doc = \"tutor_textbook.pdf\"\n",
        "        self.loader = PyPDFLoader(self.doc)\n",
        "\n",
        "        # Load the document and store it in the 'data' variable\n",
        "        self.data = self.loader.load_and_split()\n",
        "\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        self.vectordb = Chroma.from_documents(self.data, embedding=self.embeddings,\n",
        "                                 persist_directory=\".\")\n",
        "\n",
        "        # Initialize a language model with ChatOpenAI\n",
        "        self.llm = ChatOpenAI(model_name= 'gpt-3.5-turbo', temperature=0.6)\n",
        "\n",
        "        #Setup a prompt template\n",
        "        template = \"\"\"\\\n",
        "        You are an assistant for question-answering tasks.\n",
        "\n",
        "        Use the following pieces of retrieved context to answer the question.\n",
        "\n",
        "        If either the PDF or the question are not related to each other or not\n",
        "        related to any educational standard, state the following: This content is\n",
        "        not related to any educational purposes.\n",
        "\n",
        "        For example, if topics are not the same, like a java textbook is given,\n",
        "        however, the user asks about a physics question, state the following: This\n",
        "        content is not related to the inputted textbook, please select another textbook\n",
        "        and try again.\n",
        "\n",
        "        If you don't know the answer, just say that you don't know.\n",
        "\n",
        "        Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Context: {context}\n",
        "\n",
        "        Answer:\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        chain_type_kwargs = {\"prompt\": prompt}\n",
        "\n",
        "\n",
        "        # 1. Vectorstore-based retriever\n",
        "        self.vectorstore_retriever = self.vectordb.as_retriever()\n",
        "\n",
        "        # Initialize a RetrievalQA chain with the language model and vector database retriever\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(self.llm, retriever= self.vectorstore_retriever, chain_type_kwargs=chain_type_kwargs)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def update_chat_history(self, question, answer):\n",
        "        self.chat_history.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    def build_combined_context(self):\n",
        "        \"\"\"Combine chat history and document context.\"\"\"\n",
        "        # Combine all previous chat history\n",
        "        chat_context = \"\\n\".join([f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in self.chat_history])\n",
        "\n",
        "        # Fetch relevant context from the vector store based on the current question\n",
        "        if self.chat_history:\n",
        "            current_question = self.chat_history[-1]['question']\n",
        "            context_from_db = self.vectorstore_retriever.get_relevant_documents(current_question)\n",
        "        else:\n",
        "            context_from_db = self.vectorstore_retriever.get_relevant_documents(\"\")\n",
        "\n",
        "        # Convert the list of context documents into a string\n",
        "        context_str = \"\\n\".join([doc.page_content for doc in context_from_db])\n",
        "\n",
        "        # Combine both chat history and the document context\n",
        "        combined_context = f\"Chat history:\\n{chat_context}\\n\\nContext from the document:\\n{context_str}\"\n",
        "\n",
        "        return combined_context\n",
        "\n",
        "\n",
        "    def invoke(self, input_dict):\n",
        "        question = input_dict.get(\"question\")\n",
        "        combined_context = self.build_combined_context()\n",
        "\n",
        "        result = self.qa_chain.invoke({\n",
        "            \"query\": question,\n",
        "            \"context\": combined_context\n",
        "        })\n",
        "\n",
        "        self.update_chat_history(question, result['result'])\n",
        "        return result\n",
        "#Setup GenerateStudyPlan pipeline\n",
        "class GenerateStudyPlan:\n",
        "    def __init__(self):\n",
        "        self.doc = \"tutor_textbook.pdf\"\n",
        "        self.loader = PyPDFLoader(self.doc)\n",
        "\n",
        "        # Load the document and store it in the 'data' variable\n",
        "        self.data = self.loader.load_and_split()\n",
        "\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        self.vectordb = Chroma.from_documents(self.data, embedding=self.embeddings,\n",
        "                                 persist_directory=\".\")\n",
        "\n",
        "        # Initialize a language model with ChatOpenAI\n",
        "        self.llm = ChatOpenAI(model_name= 'gpt-3.5-turbo', temperature=0.6)\n",
        "\n",
        "        #Setup a prompt template\n",
        "        template = \"\"\"\\\n",
        "            You are an assistant for generating study plans on a singular subject.\n",
        "\n",
        "        Use the following pieces of retrieved context to answer the question.\n",
        "\n",
        "        If the user has given a topic to study or topics that they need focus on,\n",
        "        make the plan more focused on those topics.\n",
        "\n",
        "        For the study plan, give 10 different questions. It must all be related to\n",
        "        the topic. The questions should be made with the textbook content.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Context: {context}\n",
        "\n",
        "        Answer:\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        chain_type_kwargs = {\"prompt\": prompt}\n",
        "\n",
        "\n",
        "        # 1. Vectorstore-based retriever\n",
        "        self.vectorstore_retriever = self.vectordb.as_retriever()\n",
        "\n",
        "        # Initialize a RetrievalQA chain with the language model and vector database retriever\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(self.llm, retriever= self.vectorstore_retriever, chain_type_kwargs=chain_type_kwargs)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def update_chat_history(self, question, answer):\n",
        "        self.chat_history.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    def build_combined_context(self):\n",
        "        \"\"\"Combine chat history and document context.\"\"\"\n",
        "        # Combine all previous chat history\n",
        "        chat_context = \"\\n\".join([f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in self.chat_history])\n",
        "\n",
        "        # Fetch relevant context from the vector store based on the current question\n",
        "        if self.chat_history:\n",
        "            current_question = self.chat_history[-1]['question']\n",
        "            context_from_db = self.vectorstore_retriever.get_relevant_documents(current_question)\n",
        "        else:\n",
        "            context_from_db = self.vectorstore_retriever.get_relevant_documents(\"\")\n",
        "\n",
        "        # Convert the list of context documents into a string\n",
        "        context_str = \"\\n\".join([doc.page_content for doc in context_from_db])\n",
        "\n",
        "        # Combine both chat history and the document context\n",
        "        combined_context = f\"Chat history:\\n{chat_context}\\n\\nContext from the document:\\n{context_str}\"\n",
        "\n",
        "        return combined_context\n",
        "\n",
        "\n",
        "    def invoke(self, input_dict):\n",
        "        question = input_dict.get(\"question\")\n",
        "        combined_context = self.build_combined_context()\n",
        "\n",
        "        result = self.qa_chain.invoke({\n",
        "            \"query\": question,\n",
        "            \"context\": combined_context\n",
        "        })\n",
        "\n",
        "        self.update_chat_history(question, result['result'])\n",
        "        return result\n",
        "\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "import markdown\n",
        "\n",
        "filepath = \"./tutor_textbook.pdf\"\n",
        "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'docx', 'png', 'jpg', 'jpeg', 'gif'}\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    global url_data, prompt_data  # Access global variables\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        url_data = request.form.get(\"url\")\n",
        "        print(\"URL: \", url_data)\n",
        "        if 'file' not in request.files:\n",
        "            print('No file uploaded!')\n",
        "        else:\n",
        "          file = request.files['file']\n",
        "          file.save(filepath)\n",
        "          print(\"File saved:\", filepath)\n",
        "        if (url_data != \"\"):\n",
        "            !curl {url_data} > tutor_textbook.pdf\n",
        "        print(\"File: \",file)\n",
        "        prompt_data = request.form.get(\"prompt\")\n",
        "        base_qa_pipeline = BaseQAPipeline()\n",
        "        result = base_qa_pipeline.invoke({'question' : prompt_data})\n",
        "        print(result)\n",
        "        return render_template(\"index.html\", result=result)\n",
        "\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route('/how-it-works', methods=['GET'])\n",
        "def how_it_works():\n",
        "    return render_template('how-it-works.html')\n",
        "\n",
        "@app.route('/generate-plan', methods=['GET', \"POST\"])\n",
        "def generate_plan():\n",
        "    if request.method == \"POST\":\n",
        "        if 'file' not in request.files:\n",
        "            print('No file uploaded!')\n",
        "        else:\n",
        "          file = request.files['file']\n",
        "          file.save(filepath)\n",
        "          print(\"File saved:\", filepath)\n",
        "        print(\"File: \",file)\n",
        "        prompt_data = request.form.get(\"prompt\")\n",
        "        generate_plan = GenerateStudyPlan()\n",
        "        result = generate_plan.invoke({'question' : prompt_data})\n",
        "        result['result'] = markdown.markdown(result['result'])\n",
        "        print(result)\n",
        "        return render_template(\"generate-plan.html\", result=result)\n",
        "\n",
        "    return render_template(\"generate-plan.html\")\n",
        "\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n",
        "# Requires index.html template to be placed into templates/index.html to work\n",
        "\n",
        "\n",
        "# Url: To input textbook url. Recognized as a .pdf format. Example url: https://www.mrbigler.com/downloads/Notes-Physics-1.pdf\n",
        "# Prompt: To input question. Recognized as a string format. Example prompt: What is momentum?\n",
        "\n",
        "# Response for now is given as a JSON response with question being your prompt and response being\n",
        "# the tutor's answer.\n",
        "\n",
        "# TO USE, PRESS THE LINK DOWN IN THE OUTPUT.\n",
        "# please press CANCEL to the prompt it asks about restarting runtime to use new packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXCPgKO1dAPs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_scuFpyxM-I"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}